{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from resnets_utils import *\n",
    "from keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "import tensorflow.compat.v1 as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeNet(input_shape = (64, 64, 1), classes = 6):\n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    X = Conv2D(6, (3,3), strides = (1,1), name = 'conv1', kernel_initializer = glorot_uniform())(X_input)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = AveragePooling2D((3, 3))(X)\n",
    "    \n",
    "    X = Conv2D(16, (3,3), strides = (1,1), name = 'conv2', kernel_initializer = glorot_uniform())(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = AveragePooling2D((3, 3))(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(120, activation='relu', name='fc2', kernel_initializer = glorot_uniform())(X)\n",
    "    X = Dense(84, activation='relu', name='fc3', kernel_initializer = glorot_uniform())(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform())(X)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name='LeNet')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet = LeNet(input_shape = (280, 320, 1), classes = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1080\n",
      "number of test examples = 120\n",
      "X_train shape: (1080, 280, 320)\n",
      "Y_train shape: (1080, 6)\n",
      "X_test shape: (120, 280, 320)\n",
      "Y_test shape: (120, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
    "\n",
    "X_train1 = np.zeros((X_train.shape[0], 280, 320))\n",
    "X_test1 = np.ones((X_test.shape[0], 280, 320))\n",
    "rgb_weights = [0.2989, 0.5870, 0.1140]\n",
    "\n",
    "X_train = np.dot(X_train[...,:3], rgb_weights)\n",
    "for i in range(X_train.shape[0]):\n",
    "    X_train1[i] = cv2.resize(X_train[i], (320,280))\n",
    "X_test = np.dot(X_test[...,:3], rgb_weights)\n",
    "for i in range(X_test.shape[0]):\n",
    "    X_test1[i] = cv2.resize(X_test[i], (320,280))\n",
    "\n",
    "#plt.imshow(X_train1[0], cmap='gray')\n",
    "#plt.show()\n",
    "#plt.imshow(X_test1[0], cmap='gray')\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train1.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test1.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train1.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test1.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "34/34 [==============================] - 22s 629ms/step - loss: 2.5392 - accuracy: 0.3758\n",
      "Epoch 2/25\n",
      "34/34 [==============================] - 21s 608ms/step - loss: 0.4993 - accuracy: 0.8144\n",
      "Epoch 3/25\n",
      "34/34 [==============================] - 22s 643ms/step - loss: 0.1782 - accuracy: 0.9613\n",
      "Epoch 4/25\n",
      "34/34 [==============================] - 22s 650ms/step - loss: 0.1058 - accuracy: 0.9862\n",
      "Epoch 5/25\n",
      "34/34 [==============================] - 22s 641ms/step - loss: 0.0822 - accuracy: 0.9759\n",
      "Epoch 6/25\n",
      "34/34 [==============================] - 22s 636ms/step - loss: 0.0469 - accuracy: 0.9966\n",
      "Epoch 7/25\n",
      "34/34 [==============================] - 22s 662ms/step - loss: 0.0204 - accuracy: 1.0000\n",
      "Epoch 8/25\n",
      "34/34 [==============================] - 22s 646ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 9/25\n",
      "34/34 [==============================] - 22s 640ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 10/25\n",
      "34/34 [==============================] - 21s 631ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 11/25\n",
      "34/34 [==============================] - 22s 643ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 12/25\n",
      "34/34 [==============================] - 22s 648ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 13/25\n",
      "34/34 [==============================] - 22s 645ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 14/25\n",
      "34/34 [==============================] - 22s 646ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 15/25\n",
      "34/34 [==============================] - 22s 650ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 16/25\n",
      "34/34 [==============================] - 22s 648ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 17/25\n",
      "34/34 [==============================] - 22s 648ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 18/25\n",
      "34/34 [==============================] - 22s 649ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 19/25\n",
      "34/34 [==============================] - 22s 651ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 20/25\n",
      "34/34 [==============================] - 22s 642ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 21/25\n",
      "34/34 [==============================] - 23s 671ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 22/25\n",
      "34/34 [==============================] - 23s 671ms/step - loss: 9.4174e-04 - accuracy: 1.0000\n",
      "Epoch 23/25\n",
      "34/34 [==============================] - 23s 676ms/step - loss: 9.2143e-04 - accuracy: 1.0000\n",
      "Epoch 24/25\n",
      "34/34 [==============================] - 21s 628ms/step - loss: 8.5149e-04 - accuracy: 1.0000\n",
      "Epoch 25/25\n",
      "34/34 [==============================] - 22s 650ms/step - loss: 8.5022e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc165125b38>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LeNet.fit(X_train1, Y_train, epochs = 25, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 122ms/step - loss: 0.2970 - accuracy: 0.9167\n",
      "Loss = 0.29699742794036865\n",
      "Test Accuracy = 0.9166666865348816\n"
     ]
    }
   ],
   "source": [
    "preds = LeNet.evaluate(X_test1, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LeNet_model/assets\n"
     ]
    }
   ],
   "source": [
    "LeNet.save(\"LeNet_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
